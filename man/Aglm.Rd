% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Aglm.r
\name{aglm}
\alias{aglm}
\title{Fitting generalized linear models with algebraic methods}
\usage{
aglm(model, data, family = poisson(), control = list(...), moves, ...)
}
\arguments{
\item{model}{model specification, either in terms of a configuration matrix or a symbolic
description of the model to be fitted}

\item{data}{data, as a data frame of raw data with ordinal discrete covariates}

\item{family}{a description of the error distirbution and link function used in the model}

\item{control}{a list of arguments that control the MCMC algorithm}

\item{moves}{the markov moves for the mcmc (as columns of a
matrix).}

\item{...}{...}
}
\value{
a list containing named elements \itemize{ \item
\code{steps}: an integer matrix whose columns represent
individual samples from the mcmc. \item \code{moves}: the moves
used for the proposal distribution in the mcmc, computed with
4ti2 (note that only the positive moves are given). \item
\code{acceptProb}: the average acceptance probability of the
moves, including the thinned moves. \item \code{call}: the call.
\item \code{obs}: the summarized data.
\item \code{A}: the sufficient
statistics computing matrix.
\item \code{sufficientStatistics}: The sufficient statistics of the model.
\item \code{p.value}: the exact p-values of individual tests,
accurate to Monte-Carlo error.  these are computed as the
proportion of samples with statistics equal to or larger than
the oberved statistic.
\item \code{mid.p.value}: the mid
p.values, see Agresti pp.20--21.
\item \code{sampsStats}:
the statistics computed for each mcmc
sample.
\item \code{cells}: the number of cells in the table. }
}
\description{
Fitting generalized linear models with algebraic methods
}
\examples{

 library(ggplot2);theme_set(theme_bw())
 
 # generating data and running a poisson regression model
   # pick beta 0 and beta 1
    b0 <- 1; b1 <- 0.3

   # generate data
    n <- 5000
    x <- sample(1:5, n, replace = T)
    y <- rpois(n, lambda = exp(b0 + b1*x))
    df <- data.frame(
     x = x, 
     y = y
    )
    
    # function output
    out <- aglm(y ~ x, data = df, family = poisson(), control = list(thin = 2000))
    
    # check convergence through trace plot
    qplot(1:10000, out$sampsStats$PRs, geom = "line")
  
   # compare aglm and glm predictions with the truth
    
    # model fitting with glm
    mod <- glm(y ~ x, data = df, family = poisson())
    
    # truth
    exp(b0 + b1*(1:5))
     
    # glm predictions
    predict(mod, data.frame(x = 1:5), type = "response")
    
    # aglm predictions
    rowMeans(out$steps) / plyr::ddply(df, "x", nrow)$V1
    
    
    
 # generating data and running a logistic regression model
 
  # helper functions
  link    <- function(p) log(p/(1-p))
  invlink <- function(x) 1 / (1+exp(-x))
  
  
  # create a fake data set
  
  # one covariate
  b0 <- 0.5; b1 <- 0.2
  
  n <- 100
  x <- sample(1:5, n, replace = T)
  y <- rbinom(n = n, size = 1, prob = invlink(b0 + b1*x))
  df <- data.frame(
    x = x, 
    y = y
  )
  
  # aglm 
  out <- aglm(y ~ x, data = df, family = binomial(), control(thin = 500))
 
  # check convergence through trace plot
  qplot(1:10000, out$sampsStats$PRs, geom = "line")
  
  # using glm
  mod <- glm(y ~ x, data = df, family = binomial())
  
  # truth 
  invlink(b0 + b1*out$obs[,1])
  
  # glm predictions
  predict(mod, data.frame(x = c(1:5)), type = "response")
  
  # aglm predictions 
  rowMeans(out$steps) / plyr::ddply(df, "x", nrow)$V1
  
}
