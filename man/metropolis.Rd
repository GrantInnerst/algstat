% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/metropolis.R
\name{metropolis}
\alias{metropolis}
\alias{rawMetropolis}
\title{The Metropolis Algorithm}
\usage{
metropolis(init, moves, iter = 1000L, burn = 0L, thin = 1L,
  dist = c("hypergeometric", "uniform"), engine = c("C++", "R"))

rawMetropolis(init, moves, iter = 1000, dist = "hypergeometric")
}
\arguments{
\item{init}{the initial step}

\item{moves}{the moves to be used (the negatives will be added); they are
arranged as the columns of a matrix.}

\item{iter}{number of chain iterations}

\item{burn}{burn-in}

\item{thin}{thinning}

\item{dist}{steady-state distribution; "hypergeometric" (default) or
"uniform"}

\item{engine}{\code{"C++"} or \code{"R"}? (C++ is significantly faster)}
}
\value{
a list
}
\description{
Given a starting table (as a vector) and a collection of moves, run the
Metropolis-Hastings algorithm starting with the starting table.
}
\details{
See Algorithm 1.1.13 in LAS, the reference below.
}
\examples{

## basic use
############################################################

# move up and down integer points on the line y = 100 - x
# sampling from the hypergeometric distribution
# note: negative moves are added internally
init <- c(10L, 90L)
moves <- matrix(c(1,-1), ncol = 1)

# it helps running each of these lines several times to get a feel for things
metropolis(init, moves, iter = 10, burn = 0, thin = 1)
metropolis(init, moves, iter = 10, burn = 0, thin = 1, dist = "uniform")
metropolis(init, moves, iter = 10, burn = 0, thin = 1, engine = "R")
metropolis(init, moves, iter = 10, burn = 0, thin = 1, engine = "R", dist = "uniform")

# a bigger simulation
iter <- 1e3
out <- metropolis(init, moves, iter = iter, burn = 0, thin = 1)
hist(out$steps[1,], breaks = 100)

# view convergence through trace plot
plot(1:iter, out$steps[1,1:iter])

# sampling from the hypergeometric distribution
out <- metropolis(init, moves, iter = iter, dist = "uniform")
hist(out$steps[1,], breaks = 100)
plot(1:iter, out$steps[1,1:iter])

# look at autocorrelation
acf(out$steps[1,])


## thinning to reduce autocorrelation with the thin argument
############################################################

out <- metropolis(init, moves, iter = iter, dist = "uniform", thin = 2500)
acf(out$steps[1,])
hist(out$steps[1,], breaks = 100)



## burn in with the burn argument
############################################################

set.seed(1L)
metropolis(init, moves, iter = 10, burn = 0, thin = 1, engine = "R")

set.seed(1L)
metropolis(init, moves, iter = 10, burn = 0, thin = 1, engine = "R")

set.seed(1L)
metropolis(init, moves, iter =  5, burn = 5, thin = 1, engine = "R")

# this can't be shown as easily with the C++ engine because of seed issues



}
\references{
Drton, M., B. Sturmfels, and S. Sullivant (2009). \emph{Lectures
on Algebraic Statistics}, Basel: Birkhauser Verlag AG.
}
\author{
David Kahle
}
